%
% File semeval2020.tex
%
% Nathan Schneider
%% Based on the style files for COLING-2020 (feiliu@cs.ucf.edu & liang.huang.sh@gmail.com), which were, in turn,
%% Based on the style files for COLING-2018, which were, in turn,
%% Based on the style files for COLING-2016, which were, in turn,
%% Based on the style files for COLING-2014, which were, in turn,
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn,
%% based on the style files for ACL-2010, which were, in turn,
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{geometry}
\usepackage{coling2020}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}
\usepackage{microtype}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{courier}

\hyphenation{an-aly-sis}
\hyphenation{an-aly-ses}
\hyphenation{Sem-Eval}
%\setlength\titlebox{5cm}
\colingfinalcopy % Uncomment this line for all SemEval submissions

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{T\"uKaPo at SemEval-2020 Task 6: Def(n)tly not BERT:\\
Definition Extraction using pre-BERT Methods in a post-BERT World}

% \author{Madeeswaran Kannan \qquad Haemanth Shanthi Ponnusamy\\
% 	Department of Linguistics \\
% 	University of T\"ubingen, Germany \\
% 	{\tt \{mkannan,???\}@sfs.uni-tuebingen.de} \\}
\author{Madeeswaran Kannan \\
  Department of Linguistics \\
  University of T\"ubingen, Germany \\
  {\tt mkannan@sfs.uni-tuebingen.de} \\\And
  Haemanth Shanthi Ponnusamy \\
  Department of Linguistics \\
  University of T\"ubingen, Germany \\
  {\tt ???@sfs.uni-tuebingen.de} \\}

\date{}

\begin{document}
\setlength{\parindent}{0pt}.

\maketitle
\begin{abstract}
  We describe our system (T\"{u}KaPo) submitted for Task 6: DeftEval, at SemEval 2020.
  We developed and evaluated multiple neural network models based on CNNs and LSTMs to
  perform binary classification of sentences containing definitions. Our final model
  achieved a F1 score of 0.6851 in subtask 1.
\end{abstract}


\section{Introduction}

Definition detection and extraction has been a well-researched topic in NLP research
for over a decade.
%
% The following footnote without marker is needed for the camera-ready
% version of the paper.
% Comment out the instructions (first text) and uncomment the 8 lines
% under "final paper" for your variant of English.
%
\blfootnote{
    %
    % for review submission
    %
    % \hspace{-0.65cm}  % space normally used by the marker
    % Place licence statement here for the camera-ready version. See
    % Section~\ref{licence} of the instructions for preparing a
    % manuscript.
    %
    % % final paper: en-uk version
    %
    % \hspace{-0.65cm}  % space normally used by the marker
    % This work is licensed under a Creative Commons
    % Attribution 4.0 International Licence.
    % Licence details:
    % \url{http://creativecommons.org/licenses/by/4.0/}.
    %
    % % final paper: en-us version
    %
    \hspace{-0.65cm}  % space normally used by the marker
    This work is licensed under a Creative Commons
    Attribution 4.0 International License.
    License details:
    \url{http://creativecommons.org/licenses/by/4.0/}.
}


\section{Background}
The DeftEval shared task is based around the English-language DEFT (Definition Extraction From Texts) corpus \cite{spala-etal-2019-deft}.
It consists of annotated text extracted from the following semi-structured and free-text sources: 2017 SEC contract filings from the US Securities and
Exchange Commission EDGAR database\footnote{https://www.sec.gov/}, and open-source textbooks from OpenStax CNX\footnote{https://cnx.org/}. The
latter encompasses topics from areas of biology, history, physics, psychology, economics, sociology, and government.
Compared to similar existing definition corpora such as WCL \cite{navigli2010learning} and W00 \cite{jin2013mining}, the data offered by the DEFT corpus is
larger in size (23,746 sentences; 11,004 positive annotations) while also providing finer-grained feature annotations
(c.f figure \ref{deft-annotation-scheme}\footnote{Additionally, relationships between terms and definitions are also annotated.}).\\

The shared tasks consists of three subtasks: 1) Sentence Classification (classify if a sentence contains a definition or not),
2) Sequence Labeling (label each token with BIO tags according to the corpus specification), and 3) Relation Classification
(label the relations between each tag according to the corpus specification). We participated in the first subtask.\\

\begin{table}[]
  \centering
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{@{}ll@{}}
  \toprule
  Tag                    & Description                                                                                \\ \midrule
  Term                   & Primary term                                                                               \\
  Alias Term             & Secondary, less common name for the primary term                                           \\
  Ordered Term           & Multiple inseparable terms that have matching sets of deﬁnitions                           \\
  Referential Term       & NP reference to a previously mentioned term                                                \\
  Definition             & Primary deﬁnition of a term                                                                \\
  Secondary Definition   & Supplemental information crossing a sentence boundary that could be part of the definition \\
  Ordered Definition     & Multiple inseparable deﬁnitions that have matching sets of terms                           \\
  Referential Definition & NP reference to a previously mentioned deﬁnition                                           \\
  Qualifier              & Speciﬁc date, location, or condition under which the deﬁnition holds                       \\ \bottomrule
  \end{tabular}%
  }
  \caption{DEFT Tag Schema}
  \label{deft-annotation-scheme}
\end{table}


Training and development data is common for all three subtasks. It is presented in a tab-delimited CONLL-2003-like
 \cite{sang2003introduction} format where each line represents a token and its features:\\

\begin{small}
  \centerline{\texttt{$[TOKEN]\hspace{6pt}[SOURCE]\hspace{6pt}[START\_CHAR]\hspace{6pt}[END\_CHAR]\hspace{6pt}
  [TAG]\hspace{6pt}[TAG\_ID]\hspace{6pt}[ROOT\_ID]\hspace{6pt}[RELATION]$}}
\end{small}
\bigskip

{\small\texttt{SOURCE}} is the source text file, {\small\texttt{START\_CHAR}} and {\small\texttt{END\_CHAR}} are the character index
boundaries of the token, {\small\texttt{TAG}} is the BIO label of the token, {\small\texttt{TAG\_ID}} is the ID
associated with the {\small\texttt{TAG}}, {\small\texttt{ROOT\_ID}} is the ID associated with the root of this relation
(if any), and {\small\texttt{RELATION}} is the relation tag of the token.\\

The test data for the first subtask is presented in the following CONLL-2003-like format:
{\small\texttt{$[SENTENCE]\hspace{6pt}[BIN\_TAG]$}}. {\small\texttt{BIN\_TAG}} is $1$ if
{\small\texttt{SENTENCE}} contains a definition, $0$ otherwise. During the training for the first subtask, the training and
development datasets were converted into the same format was the test dataset using a script provided with the corpus. A positive
label was associated with every sentence that contained tokens with {\small\texttt{B-Definition}} or {\small\texttt{I-Definition}} tags;
all other sentences were associated with a negative label.


\subsection{Related Work}
In the early days of definition extraction, rule-based approaches leveraging  linguistic features showed promise.
\newcite{westerhout2009definition} used a combination of linguistic information (n-grams, syntactic features) and
structural information (position in sentence, layout) to extract definitions from Dutch texts. Such approaches, however,
were found to be dependent on language and domain and scale poorly. Later research incorporated machine learning
methods to encode lexical and syntactic features as word vectors \cite{del2014coping}. \newcite{noraset2017definition}
tackled the problem as a language modelling task over learned definition embeddings. \newcite{espinosa2015definition}
derive feature vectors from entity-linking sources and sense-disambiguated word embeddings. More recently,
\newcite{anke2018syntactically} use convolutional and recurrent neural networks over syntactic dependencies to achieve
state-of-the-art results on the WCL and W00 datasets \cite{navigli2010learning,jin2013mining}.


\section{System Overview}
We developed and iterated over multiple LSTM-based recurrent neural network models \cite{hochreiter1997long}. As our baseline,
we designated a model with a single bidirectional LSTM layer followed by two feed-forward layers and a final sigmoid read-out layer.
Token sequences were extracted from the training data's source sentences and passed as inputs to an embedding lookup layer, whose
embeddings were used as inputs to the LSTM layer.\\

To experiment with multiple features, we developed a non-sequential model that
extracted and learned representations for each type of feature. The concatenated representation of the feature embeddings was then
fed as input to a BiLSTM layer followed by a feed-forward network.\\

Finally, we also experimented with a hybrid-approach of using
convolutional layers in addition to the recurrent layers. To this end, we augmented the previous architecture by interspersing
single-dimensional convolution and max-pooling layers over the concatenated feature representation. The intuition behind this step
was to leverage the implicit feature-extraction performed by the convolutional layers to refine the final representation passed to
the recurrent layer.


\subsection{Features}
Beyond using word tokens, we experimented with different types of input primitives to bolster the informativity of the learned
feature vectors. As evidenced by previous approaches, the task of definition extraction benefits from the incorporation of syntactic
information. To facilitate this, we tested our models with part-of-speech tags, dependency labels, and head-modifiers as inputs
(individually and combined).\\

We also tested the impact of punctuations and frequency constraints on all input primitives.
Furthermore, to imbue the model with semantic and lexical information, pre-trained embeddings were used to initialise the embedding
matrices of word tokens. For this, GloVe \cite{pennington2014glove} and word2vec \cite{mikolov2013efficient} word embeddings were used.


\subsection{Experiments}


\section{Evaluation \& Results}


\section{Conclusion}


% include your own bib file like this:
\bibliographystyle{coling}
\bibliography{semeval2020}

%\begin{thebibliography}{}

%\bibitem[\protect\citename{Aho and Ullman}1972]{Aho:72}
%Alfred~V. Aho and Jeffrey~D. Ullman.
%\newblock 1972.
%\newblock {\em The Theory of Parsing, Translation and Compiling}, volume~1.
%\newblock Prentice-{Hall}, Englewood Cliffs, NJ.

%\bibitem[\protect\citename{{American Psychological Association}}1983]{APA:83}
%{American Psychological Association}.
%\newblock 1983.
%\newblock {\em Publications Manual}.
%\newblock American Psychological Association, Washington, DC.

%\bibitem[\protect\citename{{Association for Computing Machinery}}1983]{ACM:83}
%{Association for Computing Machinery}.
%\newblock 1983.
%\newblock {\em Computing Reviews}, 24(11):503--512.

%\bibitem[\protect\citename{Chandra \bgroup et al.\egroup }1981]{Chandra:81}
%Ashok~K. Chandra, Dexter~C. Kozen, and Larry~J. Stockmeyer.
%\newblock 1981.
%\newblock Alternation.
%\newblock {\em Journal of the Association for Computing Machinery},
%  28(1):114--133.

%\bibitem[\protect\citename{Gusfield}1997]{Gusfield:97}
%Dan Gusfield.
%\newblock 1997.
%\newblock {\em Algorithms on Strings, Trees and Sequences}.
%\newblock Cambridge University Press, Cambridge, UK.

%\bibitem[\protect\citename{Rasooli and Tetreault}2015]{rasooli-tetrault-2015}
%Mohammad~Sadegh Rasooli and Joel~R. Tetreault. 2015.
%\newblock {Yara parser: {A} fast and accurate dependency parser}.
%\newblock \emph{Computing Research Repository}, arXiv:1503.06733.
%\newblock Version 2.

%\bibitem[\protect\citename{Borschinger and Johnson}2011]{borsch2011}
%Benjamin Borschinger and Mark Johnson. 2011.
%\newblock A particle filter algorithm for {B}ayesian wordsegmentation.
%\newblock In \emph{Proceedings of the Australasian Language Technology Association %Workshop 2011}, pages 10--18, Canberra, Australia.

%\end{thebibliography}

\end{document}
